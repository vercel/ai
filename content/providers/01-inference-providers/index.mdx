---
title: AI SDK Providers
description: Learn how to use AI SDK providers.
---

# AI SDK Providers

The AI SDK comes with several providers that you can use to interact with different language models:

<OfficialModelCards />

There are also [community providers](./community-providers) that have been created using the [Language Model Specification](./community-providers/custom-providers).

<CommunityModelCards />

## Provider support

Not all providers support all AI SDK features. Here's a quick comparison of the capabilities of popular models:

| Provider                                                                 | Model                                               | Image Input         | Object Generation   | Tool Usage          | Tool Streaming      |
| ------------------------------------------------------------------------ | --------------------------------------------------- | ------------------- | ------------------- | ------------------- | ------------------- |
| [Google Vertex](/providers/inference-providers/google-vertex)               | `gemini-3.1-pro-preview`                            | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Google Vertex](/providers/inference-providers/google-vertex)               | `gemini-3-pro-preview`                              | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Google Vertex](/providers/inference-providers/google-vertex)               | `gemini-2.5-pro`                                    | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Google Vertex](/providers/inference-providers/google-vertex)               | `gemini-2.5-flash`                                  | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Groq](/providers/inference-providers/groq)                                 | `meta-llama/llama-4-scout-17b-16e-instruct`         | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Groq](/providers/inference-providers/groq)                                 | `llama-3.3-70b-versatile`                           | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Groq](/providers/inference-providers/groq)                                 | `deepseek-r1-distill-llama-70b`                     | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Groq](/providers/inference-providers/groq)                                 | `qwen-qwq-32b`                                      | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Groq](/providers/inference-providers/groq)                                 | `openai/gpt-oss-120b`                               | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Together AI](/providers/inference-providers/togetherai)                    | `meta-llama/Meta-Llama-3.3-70B-Instruct-Turbo`      | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> |
| [Together AI](/providers/inference-providers/togetherai)                    | `Qwen/Qwen2.5-72B-Instruct-Turbo`                   | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> |
| [Together AI](/providers/inference-providers/togetherai)                    | `deepseek-ai/DeepSeek-V3`                           | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> |
| [Together AI](/providers/inference-providers/togetherai)                    | `mistralai/Mixtral-8x22B-Instruct-v0.1`             | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Fireworks](/providers/inference-providers/fireworks)                       | `accounts/fireworks/models/deepseek-r1`             | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> |
| [Fireworks](/providers/inference-providers/fireworks)                       | `accounts/fireworks/models/deepseek-v3`             | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Cross size={18} /> |
| [Fireworks](/providers/inference-providers/fireworks)                       | `accounts/fireworks/models/llama-v3p3-70b-instruct` | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Fireworks](/providers/inference-providers/fireworks)                       | `accounts/fireworks/models/qwen2-vl-72b-instruct`   | <Check size={18} /> | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> |
| [DeepInfra](/providers/inference-providers/deepinfra)                       | `meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8` | <Check size={18} /> | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> |
| [DeepInfra](/providers/inference-providers/deepinfra)                       | `meta-llama/Llama-4-Scout-17B-16E-Instruct`         | <Check size={18} /> | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> |
| [DeepInfra](/providers/inference-providers/deepinfra)                       | `meta-llama/Llama-3.3-70B-Instruct`                 | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Cross size={18} /> |
| [DeepInfra](/providers/inference-providers/deepinfra)                       | `deepseek-ai/DeepSeek-V3`                           | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> |
| [DeepInfra](/providers/inference-providers/deepinfra)                       | `deepseek-ai/DeepSeek-R1`                           | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> | <Cross size={18} /> |
| [DeepInfra](/providers/inference-providers/deepinfra)                       | `Qwen/QwQ-32B`                                      | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Cross size={18} /> |
| [Cerebras](/providers/inference-providers/cerebras)                         | `llama3.3-70b`                                      | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Cerebras](/providers/inference-providers/cerebras)                         | `gpt-oss-120b`                                      | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Cerebras](/providers/inference-providers/cerebras)                         | `qwen-3-32b`                                        | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Hugging Face](/providers/inference-providers/huggingface)                  | `meta-llama/Llama-3.1-8B-Instruct`                  | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Hugging Face](/providers/inference-providers/huggingface)                  | `moonshotai/Kimi-K2-Instruct`                       | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Baseten](/providers/inference-providers/baseten)                           | `Qwen/Qwen3-235B-A22B-Instruct-2507`                | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Baseten](/providers/inference-providers/baseten)                           | `deepseek-ai/DeepSeek-V3.1`                         | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| [Baseten](/providers/inference-providers/baseten)                           | `moonshotai/Kimi-K2-Instruct-0905`                  | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |

<Note>
  This table is not exhaustive. Additional models can be found in the provider
  documentation pages and on the provider websites.
</Note>
