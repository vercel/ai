---
title: vectorstores
description: Learn how to use vectorstores with the AI SDK.
---

# vectorstores

[vectorstores](https://vectorstores.org) is a lightweight TypeScript library for context engineering in AI applications. It provides a unified interface for connecting vector databases to your AI application, supporting ingestion of data from various sources, loading it into vector databases, and querying it later on.

Based on a fork of [LlamaIndexTS](https://github.com/run-llama/LlamaIndexTS), it shares its syntax but vectorstores is more lightweight (~77.5kb gzip) and focuses specifically on using vector databases.

The `@ai-sdk/vectorstores` adapter provides integration between vectorstores and the AI SDK, enabling you to:

- Use any AI SDK embedding model with vectorstores
- Add tools to query vectorstores directly from AI SDK functions like `streamText` and `generateText`

## Installation

<Tabs items={['pnpm', 'npm', 'yarn']}>
  <Tab>
    <Snippet
      text="pnpm add @ai-sdk/vectorstores @vectorstores/core @vectorstores/readers"
      dark
    />
  </Tab>
  <Tab>
    <Snippet
      text="npm install @ai-sdk/vectorstores @vectorstores/core @vectorstores/readers"
      dark
    />
  </Tab>
  <Tab>
    <Snippet
      text="yarn add @ai-sdk/vectorstores @vectorstores/core @vectorstores/readers"
      dark
    />
  </Tab>
</Tabs>

<Note>
  `@vectorstores/core` is a required peer dependency for `@ai-sdk/vectorstores`.
</Note>

## Features

- **`vercelEmbedding`** - Adapter to use any AI SDK embedding model with vectorstores
- **`vectorstores`** - Tool that queries a VectorStoreIndex for relevant documents

## Example: RAG with PDF and streamText

Here's a complete example that reads a PDF document, creates a vector index, and uses it with `streamText`:

```ts filename="rag-example.ts"
import { openai } from '@ai-sdk/openai';
import { vectorstores, vercelEmbedding } from '@ai-sdk/vectorstores';
import { VectorStoreIndex } from '@vectorstores/core';
import { PDFReader } from '@vectorstores/readers/pdf';
import { stepCountIs, streamText } from 'ai';

async function main() {
  // Load the PDF document using vectorstores/readers
  const reader = new PDFReader();
  const documents = await reader.loadData('./data/ai.pdf');

  console.log(`Loaded ${documents.length} document(s) from PDF`);

  // Create the vector index with AI SDK embeddings
  const index = await VectorStoreIndex.fromDocuments(documents, {
    embedFunc: vercelEmbedding(openai.embedding('text-embedding-3-small')),
  });
  console.log('Created vector index');

  const result = await streamText({
    model: openai.chat('gpt-4o-mini'),
    prompt:
      'What is the difference between a generative model and an embedding model?',
    tools: {
      queryKnowledge: vectorstores({
        index,
        description:
          'Search the AI knowledge base for information about AI concepts.',
        similarityTopK: 3,
      }),
    },
    stopWhen: stepCountIs(5),
  });

  for await (const chunk of result.fullStream) {
    if (chunk.type === 'text-delta') {
      process.stdout.write(chunk.text);
    } else if (chunk.type === 'tool-call') {
      console.log(`TOOL CALL ${chunk.toolName} ${JSON.stringify(chunk.input)}`);
    }
  }
}

main().catch(console.error);
```

## API Reference

### `vectorstores(options)`

Creates a tool that queries a VectorStoreIndex for relevant documents.

```ts
import { vectorstores } from '@ai-sdk/vectorstores';

const searchTool = vectorstores({
  index,
  description: 'Search documents for relevant information.',
  similarityTopK: 10,
});
```

**Parameters:**

- `options`: `vectorstoresToolOptions`
  - `index`: `VectorStoreIndex` - The VectorStoreIndex to query (required)
  - `description?`: `string` - Custom description for the tool (default: "get information from your knowledge base to answer questions.")
  - `similarityTopK?`: `number` - Number of top results to retrieve (default: 10)

**Returns:** `Tool<{ query: string }, string>`

### `vercelEmbedding(model, options?)`

Creates an embedding function compatible with vectorstores from an AI SDK embedding model.

```ts
import { openai } from '@ai-sdk/openai';
import { vercelEmbedding } from '@ai-sdk/vectorstores';

const embedFunc = vercelEmbedding(openai.embedding('text-embedding-3-small'), {
  maxRetries: 3,
});
```

**Parameters:**

- `model`: `EmbeddingModel` - The AI SDK embedding model to use (required)
- `options?`: `VercelEmbeddingOptions`
  - `maxRetries?`: `number` - Maximum number of retries for embedding requests (default: 2)
  - `headers?`: `Record<string, string>` - Additional headers for the request

**Returns:** `(input: string[]) => Promise<number[][]>`

## More Resources

- [vectorstores Documentation](https://vectorstores.org) - Official documentation for vectorstores
- [Installation Guide](https://vectorstores.org/getting_started/installation/) - Getting started with vectorstores
- [AI SDK Examples](https://github.com/vercel/ai/tree/main/examples/ai-core/src/vectorstores) - vectorstores examples in the AI SDK repository
- [vectorstores Examples](https://vectorstores.org/getting_started/examples/) - More examples from the vectorstores documentation
