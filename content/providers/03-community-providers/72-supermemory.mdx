---
title: 'Supermemory'
description: 'Learn how to use the Supermemory AI SDK provider for the Vercel AI SDK.'
---

# Supermemory

[Supermemory](https://supermemory.ai) is a long-term memory platform that adds persistent, self-growing memory to your AI applications. The Supermemory provider for the AI SDK enables you to build AI applications with memory that works like the human brain:

- **Persistent Memory**: Long-term storage that grows with each interaction
- **Semantic Search**: Find relevant memories using natural language queries
- **Automatic Memory Management**: AI automatically saves and retrieves relevant information
- **Easy Integration**: Simple setup with existing AI SDK applications
- **Memory Router**: Direct integration with language model providers
- **Free Tier Available**: Get started with a free API key

Learn more about Supermemory's capabilities in the [Supermemory Documentation](https://supermemory.ai/docs/ai-sdk/overview).

## Setup

The Supermemory provider is available in the `@supermemory/tools` module. You can install it with:

<Tabs items={['pnpm', 'npm', 'yarn', 'bun']}>
  <Tab>
    <Snippet text="pnpm add @supermemory/tools" dark />
  </Tab>
  <Tab>
    <Snippet text="npm install @supermemory/tools" dark />
  </Tab>
  <Tab>
    <Snippet text="yarn add @supermemory/tools" dark />
  </Tab>
  <Tab>
    <Snippet text="bun add @supermemory/tools" dark />
  </Tab>
</Tabs>

## Provider Instance

You can obtain your Supermemory API key for free at [https://console.supermemory.ai](https://console.supermemory.ai).

There are three ways to integrate Supermemory with your AI applications:

**1. Using the withSupermemory Middleware (Recommended)**

Use the `withSupermemory` middleware for automatic memory integration:

```typescript
import { withSupermemory } from '@supermemory/tools/ai-sdk';
import { openai } from '@ai-sdk/openai';

const modelWithMemory = withSupermemory(openai('gpt-4'), 'user-id');
```

**2. Using Supermemory Tools**

Import and use Supermemory tools with your existing AI SDK setup:

```typescript
import { supermemoryTools } from '@supermemory/tools/ai-sdk';
```

**3. Using the Memory Router**

Use the Memory Router for direct integration with language model providers:

```typescript
import { createAnthropic } from '@ai-sdk/anthropic';

const supermemoryRouter = createAnthropic({
  baseUrl: 'https://api.supermemory.ai/v3/https://api.anthropic.com/v1',
  apiKey: 'your-provider-api-key',
  headers: {
    'x-supermemory-api-key': 'supermemory-api-key',
    'x-sm-conversation-id': 'conversation-id',
  },
});
```

## Examples

Here are examples of using Supermemory with the AI SDK:

### AI SDK Middleware with Supermemory

- `withSupermemory` will take advantage supermemory profile v4 endpoint personalized based on container tag
- Make sure you have `SUPERMEMORY_API_KEY` in env

```typescript
import { generateText } from 'ai';
import { withSupermemory } from '@supermemory/tools/ai-sdk';
import { openai } from '@ai-sdk/openai';

const modelWithMemory = withSupermemory(openai('gpt-5'), 'user_id_life');

const result = await generateText({
  model: modelWithMemory,
  messages: [{ role: 'user', content: 'where do i live?' }],
});

console.log(result.text);
```

### Conversation Grouping

Use the `conversationId` option to group messages into a single document for contextual memory generation:

```typescript
import { generateText } from 'ai';
import { withSupermemory } from '@supermemory/tools/ai-sdk';
import { openai } from '@ai-sdk/openai';

const modelWithMemory = withSupermemory(openai('gpt-5'), 'user_id_life', {
  conversationId: 'conversation-456',
});

const result = await generateText({
  model: modelWithMemory,
  messages: [{ role: 'user', content: 'where do i live?' }],
});

console.log(result.text);
```

### Automatic Memory Capture

The middleware can automatically save user messages as memories:

**Always Save Memories** - Automatically stores every user message as a memory:

```typescript
import { generateText } from 'ai';
import { withSupermemory } from '@supermemory/tools/ai-sdk';
import { openai } from '@ai-sdk/openai';

const modelWithAutoSave = withSupermemory(openai('gpt-4'), 'user-123', {
  addMemory: 'always',
});

const result = await generateText({
  model: modelWithAutoSave,
  messages: [
    { role: 'user', content: 'I prefer React with TypeScript for my projects' },
  ],
});
// This message will be automatically saved as a memory
```

**Never Save Memories (Default)** - Only retrieves memories without storing new ones:

```typescript
const modelWithNoSave = withSupermemory(openai('gpt-4'), 'user-123');
```

### Using Supermemory Tools

```typescript
import {
  supermemoryTools,
  searchMemoriesTool,
  addMemoryTool,
} from '@supermemory/tools/ai-sdk';
import { createOpenAI } from '@ai-sdk/openai';
import { generateText } from 'ai';

const openai = createOpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
});

// Create all tools
const tools = supermemoryTools(process.env.SUPERMEMORY_API_KEY!, {
  containerTags: ['your-user-id'],
});

// Use with AI SDK
const result = await generateText({
  model: openai('gpt-5'),
  messages: [
    {
      role: 'user',
      content: 'What do you remember about my preferences?',
    },
  ],
  tools,
});

// Or create individual tools
const searchTool = searchMemoriesTool(process.env.SUPERMEMORY_API_KEY!, {
  projectId: 'your-project-id',
});

const addTool = addMemoryTool(process.env.SUPERMEMORY_API_KEY!, {
  projectId: 'your-project-id',
});
```

### Using Memory Router

```javascript
import { streamText } from 'ai';
import { createAnthropic } from '@ai-sdk/anthropic';

const supermemoryRouter = createAnthropic({
  baseUrl: 'https://api.supermemory.ai/v3/https://api.anthropic.com/v1',
  apiKey: 'your-provider-api-key',
  headers: {
    'x-supermemory-api-key': 'supermemory-api-key',
    'x-sm-conversation-id': 'conversation-id',
  },
});

const result = streamText({
  model: supermemoryRouter('claude-3-sonnet'),
  messages: [
    { role: 'user', content: 'Hello! Remember that I love TypeScript.' },
  ],
});
```

## Advanced Features

### Verbose Mode

Enable verbose logging to see detailed information about memory search and transformation:

```typescript
import { generateText } from 'ai';
import { withSupermemory } from '@supermemory/tools/ai-sdk';
import { openai } from '@ai-sdk/openai';

const modelWithMemory = withSupermemory(openai('gpt-5'), 'user_id_life', {
  verbose: true,
});

const result = await generateText({
  model: modelWithMemory,
  messages: [{ role: 'user', content: 'where do i live?' }],
});

console.log(result.text);
```

When verbose mode is enabled, you'll see console output like:

```
[supermemory] Searching memories for container: user_id_life
[supermemory] User message: where do i live?
[supermemory] System prompt exists: false
[supermemory] Found 3 memories
[supermemory] Memory content: You live in San Francisco, California. Your address is 123 Main Street...
[supermemory] Creating new system prompt with memories
```

### Memory Search Modes

The middleware supports different modes for memory retrieval:

**Profile Mode (Default)** - Retrieves user profile memories without query filtering:

```typescript
import { generateText } from 'ai';
import { withSupermemory } from '@supermemory/tools/ai-sdk';
import { openai } from '@ai-sdk/openai';

// Uses profile mode by default - gets all user profile memories
const modelWithMemory = withSupermemory(openai('gpt-4'), 'user-123');

// Explicitly specify profile mode
const modelWithProfile = withSupermemory(openai('gpt-4'), 'user-123', {
  mode: 'profile',
});

const result = await generateText({
  model: modelWithMemory,
  messages: [{ role: 'user', content: 'What do you know about me?' }],
});
```

**Query Mode** - Searches memories based on the user's message:

```typescript
import { generateText } from 'ai';
import { withSupermemory } from '@supermemory/tools/ai-sdk';
import { openai } from '@ai-sdk/openai';

const modelWithQuery = withSupermemory(openai('gpt-4'), 'user-123', {
  mode: 'query',
});

const result = await generateText({
  model: modelWithQuery,
  messages: [
    { role: 'user', content: "What's my favorite programming language?" },
  ],
});
```

**Full Mode** - Combines both profile and query results:

```typescript
import { generateText } from 'ai';
import { withSupermemory } from '@supermemory/tools/ai-sdk';
import { openai } from '@ai-sdk/openai';

const modelWithFull = withSupermemory(openai('gpt-4'), 'user-123', {
  mode: 'full',
});

const result = await generateText({
  model: modelWithFull,
  messages: [{ role: 'user', content: 'Tell me about my preferences' }],
});
```

**Combined Options** - Use verbose logging with specific modes and memory storage:

```typescript
const modelWithOptions = withSupermemory(openai('gpt-4'), 'user-123', {
  mode: 'profile',
  addMemory: 'always',
  verbose: true,
});
```

For more information about these features and advanced configuration options, visit the [Supermemory Documentation](https://supermemory.ai/docs/).

## Additional Resources

- [Supermemory Documentation](https://supermemory.ai/docs/?ref=ai-sdk)
- [AI SDK Integration Cookbook](https://supermemory.ai/docs/cookbook/ai-sdk-integration)
- [Supermemory Console](https://console.supermemory.ai)
- [Memory Engine Blog Post](https://supermemory.ai/blog/memory-engine/)
