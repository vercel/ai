---
title: Helicone
description: Helicone Provider for the AI SDK
---

# Helicone

The [Helicone AI Gateway](https://helicone.ai/) provides you with access to hundreds of AI models, as well as tracing and monitoring through our embedded observability platform.

- **üåê Unified model access**: Use one API key to access hundreds of models from leading providers like Anthropic, Google, Meta, and more.
- **‚ö° Smart provider selection**: Always hit the cheapest provider, and always aware of provider uptimes and your rate limits. Built-in strategies include model-based latency routing (fastest model), provider latency-based P2C + PeakEWMA (fastest provider), weighted distribution (based on model weight), and cost optimization (cheapest option).
- **üöÄ Improve performance**: Cache responses to reduce costs and latency.
- **üìä Simplified tracing**: Monitor performance and debug issues with Helicone observability embedded, including OpenTelemetry support for logs, metrics, and traces.

Learn more about Helicone's capabilities in the [Helicone Documentation](https://helicone.ai/docs).

## Setup

The Helicone provider is available in the `@helicone/ai-sdk-provider` package. You can install it with:

<Tabs items={['pnpm', 'npm', 'yarn', 'bun']}>
  <Tab>
    <Snippet text="pnpm add @helicone/ai-sdk-provider" dark />
  </Tab>
  <Tab>
    <Snippet text="npm install @helicone/ai-sdk-provider" dark />
  </Tab>
  <Tab>
    <Snippet text="yarn add @helicone/ai-sdk-provider" dark />
  </Tab>
  <Tab>
    <Snippet text="bun add @helicone/ai-sdk-provider" dark />
  </Tab>
</Tabs>

## Get started

To get started with Helicone, use the `createHelicone` function to create a provider instance. Then query any model you like.

```typescript
import { createHelicone } from '@helicone/ai-sdk-provider';
import { generateText } from 'ai';

const helicone = createHelicone({
  apiKey: process.env.HELICONE_API_KEY
});

const result = await generateText({
  model: helicone("claude-3.7-sonnet"),
  prompt: "Write a haiku about artificial intelligence",
});

console.log(result.text);
```

You can obtain your Helicone API key from the [Helicone Dashboard](https://us.helicone.ai/settings/api-keys).

## Examples

Here are examples of using Helicone with the AI SDK.

### `generateText`

```javascript
import { createHelicone } from '@helicone/ai-sdk-provider';
import { generateText } from 'ai';

const helicone = createHelicone({
  apiKey: process.env.HELICONE_API_KEY
});

const { text } = await generateText({
  model: helicone('claude-3.7-sonnet'),
  prompt: 'What is Helicone?'
});

console.log(text);
```

### `streamText`

```javascript
const helicone = createHelicone({
  apiKey: process.env.HELICONE_API_KEY
});

const result = await streamText({
  model: helicone('gpt-4o-mini'),
  prompt: 'Write a short story about a robot learning to paint',
  maxOutputTokens: 300
});

for await (const chunk of result.textStream) {
  process.stdout.write(chunk);
}

console.log('\n\nStream completed!');
```

## Advanced Features

Helicone offers several advanced features to enhance your AI applications:

1. **Model flexibility**: Switch between hundreds of models without changing your code or managing multiple API keys.

2. **Cost management**: Manage costs per model in real-time through Helicone's LLM observability dashboard.

3. **Observability**: Access comprehensive analytics and logs for all your requests through Helicone's LLM observability dashboard.

4. **Prompts management**: Manage prompts and versioning through the Helicone dashboard.

5. **Caching**: Cache responses to reduce costs and latency.

6. **Regular updates**: Automatic access to new models and features as they become available.

For more information about these features and advanced configuration options, visit the [Helicone Documentation](https://docs.helicone.ai).
