---
title: Telemetry
description: Using OpenTelemetry with AI SDK Core
---

# Telemetry

<Note type="warning">
  This feature is experimental and may change in the future. Currently, only the
  `generateText` and `streamText` functions support telemetry.
</Note>

The Vercel AI SDK uses [OpenTelemetry](https://opentelemetry.io/) to collect telemetry data.
OpenTelemetry is an open-source observability framework designed to provide
standardized instrumentation for collecting telemetry data.

## Enabling telemetry

For Next.js applications, please follow the [Next.js OpenTelemetry guide](https://nextjs.org/docs/app/building-your-application/optimizing/open-telemetry) to enable telemetry first.

You can then use the `experimental_telemetry` option to enable telemetry on specific function calls while the feature is experimental:

```ts highlight="4"
const result = await generateText({
  model: openai('gpt-4-turbo'),
  prompt: 'Write a short story about a cat.',
  experimental_telemetry: { isEnabled: true },
});
```

The following functions currently support telemetry:

- `generateText`
- `streamText`
- `generateObject`
- `embed`
- `embedMany`

## Telemetry Metadata

You can provide a `functionId` to identify the function that the telemetry data is for,
and `metadata` to include additional information in the telemetry data.

```ts highlight="6-10"
const result = await generateText({
  model: openai('gpt-4-turbo'),
  prompt: 'Write a short story about a cat.',
  experimental_telemetry: {
    isEnabled: true,
    functionId: 'my-awesome-function',
    metadata: {
      something: 'custom',
      someOtherThing: 'other-value',
    },
  },
});
```

## Collected Data

### generateText function

`generateText` records 3 types of spans:

- `ai.generateText`: the full length of the generateText call. It contains 1 or more `ai.generateText.doGenerate` spans.
  It contains the [basic LLM span information](#basic-llm-span-information) and the following attributes:
  - `operation.name`: `ai.generateText`
  - `ai.prompt`: the prompt that was used when calling `generateText`
  - `ai.settings.maxToolRoundtrips`: the maximum number of tool roundtrips that were set
- `ai.generateText.doGenerate`: a provider doGenerate call. It can contain `ai.toolCall` spans.
  It contains the [basic LLM span information](#basic-llm-span-information) and the following attributes:
  - `operation.name`: `ai.generateText`
  - `ai.prompt.format`: the format of the prompt
  - `ai.prompt.messages`: the messages that were passed into the provider
- `ai.toolCall`: a tool call that is made as part of the generateText call. See [Tool call spans](#tool-call-spans) for more details.

### streamText function

`streamText` records 3 types of spans:

- `ai.streamText`: the full length of the streamText call. It contains a `ai.streamText.doStream` span.
  It contains the [basic LLM span information](#basic-llm-span-information) and the following attributes:
  - `operation.name`: `ai.streamText`
  - `ai.prompt`: the prompt that was used when calling `streamText`
- `ai.streamText.doStream`: a provider doStream call.
  This span contains an `ai.stream.firstChunk` event that is emitted when the first chunk of the stream is received.
  The `doStream` span can also contain `ai.toolCall` spans.
  It contains the [basic LLM span information](#basic-llm-span-information) and the following attributes:
  - `operation.name`: `ai.streamText`
  - `ai.prompt.format`: the format of the prompt
  - `ai.prompt.messages`: the messages that were passed into the provider
- `ai.toolCall`: a tool call that is made as part of the generateText call. See [Tool call spans](#tool-call-spans) for more details.

### generateObject function

`generateObject` records 2 types of spans:

- `ai.generateObject`: the full length of the generateObject call. It contains 1 or more `ai.generateObject.doGenerate` spans.
  It contains the [basic LLM span information](#basic-llm-span-information) and the following attributes:
  - `operation.name`: `ai.generateObject`
  - `ai.prompt`: the prompt that was used when calling `generateObject`
  - `ai.settings.mode`: the object generation mode
- `ai.generateObject.doGenerate`: a provider doGenerate call.
  It contains the [basic LLM span information](#basic-llm-span-information) and the following attributes:
  - `operation.name`: `ai.generateObject`
  - `ai.prompt.format`: the format of the prompt
  - `ai.prompt.messages`: the messages that were passed into the provider
  - `ai.settings.mode`: the object generation mode

### embed function

`embed` records 2 types of spans:

- `ai.embed`: the full length of the embed call. It contains 1 `ai.embed.doEmbed` spans.
  It contains the [basic embedding span information](#basic-embedding-span-information) and the following attributes:
  - `operation.name`: `ai.embed`
  - `ai.value`: the value that was passed into the `embed` function
  - `ai.embedding`: a JSON-stringified embedding
- `ai.embed.doEmbed`: a provider doEmbed call.
  It contains the [basic embedding span information](#basic-embedding-span-information) and the following attributes:
  - `operation.name`: `ai.embed`
  - `ai.values`: the values that were passed into the provider (array)
  - `ai.embeddings`: an array of JSON-stringified embeddings

### embedMany function

`embedMany` records 2 types of spans:

- `ai.embedMany`: the full length of the embedMany call. It contains 1 or more `ai.embedMany.doEmbed` spans.
  It contains the [basic embedding span information](#basic-embedding-span-information) and the following attributes:
  - `operation.name`: `ai.embedMany`
  - `ai.values`: the values that were passed into the `embedMany` function
  - `ai.embeddings`: an array of JSON-stringified embedding
- `ai.embedMany.doEmbed`: a provider doEmbed call.
  It contains the [basic embedding span information](#basic-embedding-span-information) and the following attributes:
  - `operation.name`: `ai.embedMany`
  - `ai.values`: the values that were sent to the provider
  - `ai.embeddings`: an array of JSON-stringified embeddings for each value

## Span Details

### Basic LLM span information

Many spans that use LLMs (`ai.generateText`, `ai.generateText.doGenerate`, `ai.streamText`, `ai.streamText.doStream`,
`ai.generateObject`, `ai.generateObject.doGenerate`) contain the following attributes:

- `ai.finishReason`: the reason why the generation finished
- `ai.model.id`: the id of the model
- `ai.model.provider`: the provider of the model
- `ai.request.headers.*`: the request headers that were passed in through `headers`
- `ai.result.text`: the text that was generated
- `ai.result.toolCalls`: the tool calls that were made as part of the generation (stringified JSON)
- `ai.settings.maxRetries`: the maximum number of retries that were set
- `ai.telemetry.functionId`: the functionId that was set through `telemetry.functionId`
- `ai.telemetry.metadata.*`: the metadata that was passed in through `telemetry.metadata`
- `ai.usage.completionTokens`: the number of completion tokens that were used
- `ai.usage.promptTokens`: the number of prompt tokens that were used
- `resource.name`: the functionId that was set through `telemetry.functionId`

### Basic embedding span information

Many spans that use embedding models (`ai.embed`, `ai.embed.doEmbed`, `ai.embedMany`, `ai.embedMany.doEmbed`) contain the following attributes:

- `ai.finishReason`: the reason why the generation finished
- `ai.model.id`: the id of the model
- `ai.model.provider`: the provider of the model
- `ai.request.headers.*`: the request headers that were passed in through `headers`
- `ai.settings.maxRetries`: the maximum number of retries that were set
- `ai.telemetry.functionId`: the functionId that was set through `telemetry.functionId`
- `ai.telemetry.metadata.*`: the metadata that was passed in through `telemetry.metadata`
- `ai.usage.tokens`: the number of tokens that were used
- `resource.name`: the functionId that was set through `telemetry.functionId`

### Tool call spans

Tool call spans (`ai.toolCall`) contain the following attributes:

- `ai.toolCall.name`: the name of the tool
- `ai.toolCall.id`: the id of the tool call
- `ai.toolCall.args`: the parameters of the tool call
- `ai.toolCall.result`: the result of the tool call. Only available if the tool call is successful and the result is serializable.
