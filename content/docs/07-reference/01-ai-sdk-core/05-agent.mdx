---
title: Agent
description: API Reference for the Agent class.
---

# `Agent`

Creates a reusable AI agent that can generate text, stream responses, and use tools across multiple steps.

It is ideal for building autonomous AI systems that need to perform complex, multi-step tasks with tool calling capabilities. Unlike single-step functions like `generateText`, agents can iteratively call tools and make decisions based on intermediate results.

```ts
import { Experimental_Agent as Agent } from 'ai';

const agent = new Agent({
  model: 'openai/gpt-4o',
  system: 'You are a helpful assistant.',
  tools: {
    weather: weatherTool,
    calculator: calculatorTool,
  },
});

const { text } = await agent.generate({
  prompt: 'What is the weather in NYC?',
});

console.log(text);
```

To see `Agent` in action, check out [these examples](#examples).

## Import

<Snippet
  text={`import { Experimental_Agent as Agent } from "ai"`}
  prompt={false}
/>

## Constructor

### Parameters

<PropertiesTable
  content={[
    {
      name: 'model',
      type: 'LanguageModel',
      isRequired: true,
      description: 'The language model to use.',
    },
    {
      name: 'system',
      type: 'string',
      description:
        'The system prompt to use that specifies the behavior of the model.',
    },
    {
      name: 'tools',
      type: 'Record<string, Tool>',
      description:
        'The tools that the model can call. The model needs to support calling tools.',
    },
    {
      name: 'toolChoice',
      type: 'ToolChoice',
      description:
        "The tool choice strategy. Options: 'auto' | 'none' | 'required' | { type: 'tool', toolName: string }. Default: 'auto'",
    },
    {
      name: 'stopWhen',
      type: 'StopCondition | StopCondition[]',
      description:
        'Condition for stopping the generation when there are tool results in the last step. Default: stepCountIs(1)',
    },
    {
      name: 'activeTools',
      type: 'Array<string>',
      description:
        'Limits the tools that are available for the model to call without changing the tool call and result types.',
    },
    {
      name: 'experimental_output',
      type: 'Output',
      description:
        'Optional specification for parsing structured outputs from the LLM response.',
    },
    {
      name: 'prepareStep',
      type: 'PrepareStepFunction',
      description:
        'Optional function that you can use to provide different settings for a step.',
    },
    {
      name: 'experimental_repairToolCall',
      type: 'ToolCallRepairFunction',
      description:
        'A function that attempts to repair a tool call that failed to parse.',
    },
    {
      name: 'onStepFinish',
      type: 'GenerateTextOnStepFinishCallback',
      description:
        'Callback that is called when each step (LLM call) is finished, including intermediate steps.',
    },
    {
      name: 'experimental_context',
      type: 'unknown',
      description:
        'Context that is passed into tool calls. Experimental (can break in patch releases).',
    },
    {
      name: 'experimental_telemetry',
      type: 'TelemetrySettings',
      description: 'Optional telemetry configuration (experimental).',
    },
    {
      name: 'maxOutputTokens',
      type: 'number',
      description: 'Maximum number of tokens to generate.',
    },
    {
      name: 'temperature',
      type: 'number',
      description:
        'Temperature setting. The value is passed through to the provider. The range depends on the provider and model.',
    },
    {
      name: 'topP',
      type: 'number',
      description:
        'Top-p sampling setting. The value is passed through to the provider. The range depends on the provider and model.',
    },
    {
      name: 'topK',
      type: 'number',
      description:
        'Top-k sampling setting. The value is passed through to the provider. The range depends on the provider and model.',
    },
    {
      name: 'presencePenalty',
      type: 'number',
      description:
        'Presence penalty setting. The value is passed through to the provider. The range depends on the provider and model.',
    },
    {
      name: 'frequencyPenalty',
      type: 'number',
      description:
        'Frequency penalty setting. The value is passed through to the provider. The range depends on the provider and model.',
    },
    {
      name: 'stopSequences',
      type: 'string[]',
      description:
        'Stop sequences to use. The value is passed through to the provider.',
    },
    {
      name: 'seed',
      type: 'number',
      description:
        'Seed for random number generation. The value is passed through to the provider.',
    },
    {
      name: 'maxRetries',
      type: 'number',
      description: 'Maximum number of retries. Default: 2.',
    },
    {
      name: 'abortSignal',
      type: 'AbortSignal',
      description:
        'An optional abort signal that can be used to cancel the call.',
    },
  ]}
/>

## Methods

### `generate()`

Generates text and calls tools for a given prompt. Returns a promise that resolves to a `GenerateTextResult`.

```ts
const result = await agent.generate({
  prompt: 'What is the weather like?',
});
```

<PropertiesTable
  content={[
    {
      name: 'prompt',
      type: 'string | Array<ModelMessage>',
      description: 'A text prompt.',
    },
    {
      name: 'messages',
      type: 'Array<SystemModelMessage | UserModelMessage | AssistantModelMessage | ToolModelMessage>',
      description: 'A list of messages that represent a conversation.',
    },
    {
      name: 'providerMetadata',
      type: 'ProviderMetadata',
      isOptional: true,
      description:
        'Additional provider-specific metadata. They are passed through from the provider to the AI SDK and enable provider-specific results that can be fully encapsulated in the provider.',
    },
    {
      name: 'providerOptions',
      type: 'ProviderOptions',
      isOptional: true,
      description:
        'Additional provider-specific metadata. They are passed through to the provider from the AI SDK and enable provider-specific functionality that can be fully encapsulated in the provider.',
    },
    {
      name: 'system',
      type: 'string',
      isOptional: true,
      description:
        'The system prompt to use that specifies the behavior of the model.',
    },
  ]}
/>

#### Returns

The `generate()` method returns a `GenerateTextResult` object with the same properties as [`generateText`](/docs/reference/ai-sdk-core/generate-text#returns).

### `stream()`

Streams text and calls tools for a given prompt. Returns a `StreamTextResult` that can be used to iterate over the stream.

```ts
const stream = agent.stream({
  prompt: 'Tell me a story about a robot.',
});

for await (const chunk of stream.textStream) {
  console.log(chunk);
}
```

<PropertiesTable
  content={[
    {
      name: 'prompt',
      type: 'string | Array<ModelMessage>',
      description: 'A text prompt.',
    },
    {
      name: 'messages',
      type: 'Array<SystemModelMessage | UserModelMessage | AssistantModelMessage | ToolModelMessage>',
      description: 'A list of messages that represent a conversation.',
    },
    {
      name: 'providerMetadata',
      type: 'ProviderMetadata',
      isOptional: true,
      description:
        'Additional provider-specific metadata. They are passed through from the provider to the AI SDK and enable provider-specific results that can be fully encapsulated in the provider.',
    },
    {
      name: 'providerOptions',
      type: 'ProviderOptions',
      isOptional: true,
      description:
        'Additional provider-specific metadata. They are passed through to the provider from the AI SDK and enable provider-specific functionality that can be fully encapsulated in the provider.',
    },
    {
      name: 'system',
      type: 'string',
      isOptional: true,
      description:
        'The system prompt to use that specifies the behavior of the model.',
    },
  ]}
/>

#### Returns

The `stream()` method returns a `StreamTextResult` object with the same properties as [`streamText`](/docs/reference/ai-sdk-core/stream-text#returns).

### `respond()`

Creates a Response object that streams UI messages to the client. This method is particularly useful for building chat interfaces in web applications.

```ts
export async function POST(request: Request) {
  const { messages } = await request.json();

  return agent.respond({
    messages,
  });
}
```

<PropertiesTable
  content={[
    {
      name: 'messages',
      type: 'UIMessage[]',
      isRequired: true,
      description: 'Array of UI messages to process.',
    },
  ]}
/>

#### Returns

Returns a `Response` object that streams UI messages to the client in the format expected by the `useChat` hook and other UI integrations.

## Types

### `InferAgentUIMessage`

Infers the UI message type of an agent, useful for type-safe message handling in TypeScript applications.

```ts
import {
  Experimental_Agent as Agent,
  Experimental_InferAgentUIMessage as InferAgentUIMessage,
} from 'ai';

const weatherAgent = new Agent({
  model: 'openai/gpt-4o',
  tools: { weather: weatherTool },
});

type WeatherAgentUIMessage = InferAgentUIMessage<typeof weatherAgent>;
```

## Examples

### Basic Agent with Tools

Create an agent that can use multiple tools to answer questions:

```ts
import { Experimental_Agent as Agent, stepCountIs } from 'ai';
import { weatherTool, calculatorTool } from './tools';

const assistant = new Agent({
  model: 'openai/gpt-4o',
  system: 'You are a helpful assistant.',
  tools: {
    weather: weatherTool,
    calculator: calculatorTool,
  },
  stopWhen: stepCountIs(3),
});

// Generate a response
const result = await assistant.generate({
  prompt: 'What is the weather in NYC and what is 100 * 25?',
});

console.log(result.text);
console.log(result.steps); // Array of all steps taken
```

### Streaming Agent Response

Stream responses for real-time interaction:

```ts
const agent = new Agent({
  model: 'openai/gpt-4o',
  system: 'You are a creative storyteller.',
});

const stream = agent.stream({
  prompt: 'Tell me a short story about a time traveler.',
});

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}
```

### Agent with Output Parsing

Parse structured output from agent responses:

```ts
import { z } from 'zod';

const analysisAgent = new Agent({
  model: 'openai/gpt-4o',
  experimental_output: {
    schema: z.object({
      sentiment: z.enum(['positive', 'negative', 'neutral']),
      score: z.number(),
      summary: z.string(),
    }),
  },
});

const result = await analysisAgent.generate({
  prompt: 'Analyze this review: "The product exceeded my expectations!"',
});

console.log(result.experimental_output); // Typed as { sentiment: 'positive' | 'negative' | 'neutral', score: number, summary: string }
```

### Next.js Route Handler

Use an agent in a Next.js API route:

```ts
// app/api/chat/route.ts
import { Experimental_Agent as Agent } from 'ai';

const agent = new Agent({
  model: 'openai/gpt-4o',
  system: 'You are a helpful assistant.',
  tools: {
    // your tools here
  },
});

export async function POST(request: Request) {
  const { messages } = await request.json();

  return agent.respond({
    messages,
  });
}
```
