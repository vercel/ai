---
title: High memory usage when processing many images
description: Troubleshooting high memory usage when using generateText or streamText with many images
---

# High memory usage when processing many images

## Issue

When using `generateText` or `streamText` with many images (e.g., in a loop or batch processing), you may notice:

- Memory usage grows continuously and doesn't decrease
- Application eventually runs out of memory
- Memory is not reclaimed even after garbage collection

This is especially noticeable when using `experimental_download` to process images from URLs, or when sending base64-encoded images in prompts.

## Background

By default, the AI SDK excludes request and response bodies from step results to reduce memory usage. However, if you explicitly opt in to including bodies via the `include` option, the request body will contain the base64-encoded image data, which can be very large (a single image can be 1MB+ when base64 encoded). If you process many images and keep references to the results, this data accumulates in memory.

For example, processing 100 images of 500KB each with `include: { requestBody: true }` would include ~50MB+ of request body data in memory.

## Solution

The default behavior already excludes bodies. If you have opted in to including bodies and are experiencing memory issues, either remove the `include` option or explicitly set the values to `false`:

```ts
import { generateText } from 'ai';
import { openai } from '@ai-sdk/openai';

const result = await generateText({
  model: openai('gpt-4o'),
  messages: [
    {
      role: 'user',
      content: [
        { type: 'text', text: 'Describe this image' },
        { type: 'image', image: imageUrl },
      ],
    },
  ],
  // Bodies are excluded by default, but you can explicitly disable them:
  // include: { requestBody: false, responseBody: false },
});
```

### Options

The `include` option accepts:

- `requestBody`: Set to `true` to include the request body in step results. This is where base64-encoded images are stored. Default: `false`. Available in both `generateText` and `streamText`.
- `responseBody`: Set to `true` to include the response body in step results. Default: `false`. Only available in `generateText`.

### When to use

If you need access to `result.request.body` or `result.response.body` for debugging or logging, you can enable inclusion:

```ts
const result = await generateText({
  model: openai('gpt-4o'),
  prompt: 'Hello',
  include: { requestBody: true, responseBody: true },
});
```

Be aware that enabling inclusion when processing many large payloads (e.g., images) can lead to high memory usage.

### Trade-offs

When you enable body inclusion:

- You will have access to `result.request.body` and `result.response.body`
- Memory usage will increase, especially when processing images or large files
- Consider extracting the data you need before the next iteration to avoid accumulating large objects in memory

## Learn more

- [`generateText` API Reference](/docs/reference/ai-sdk-core/generate-text)
- [`streamText` API Reference](/docs/reference/ai-sdk-core/stream-text)
