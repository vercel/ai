---
title: Chrome AI
description: Learn how to use the Chrome AI provider for the AI SDK.
---

# ChromeAI

[jeasonstudio/chrome-ai](https://github.com/jeasonstudio/chrome-ai) is a community provider that uses [Chrome Built-in AI](https://developer.chrome.com/docs/ai/built-in) to provide language model support for the AI SDK.

<Note type="warning">
  This module is under development and may contain errors and frequent
  incompatible changes.
</Note>

## Setup

The ChromeAI provider is available in the `chrome-ai` module. You can install it with:

<Tabs items={['pnpm', 'npm', 'yarn']}>
  <Tab>
    <Snippet text="pnpm add chrome-ai" dark />
  </Tab>
  <Tab>
    <Snippet text="npm install chrome-ai" dark />
  </Tab>
  <Tab>
    <Snippet text="yarn add chrome-ai" dark />
  </Tab>
</Tabs>

### Enabling AI in Chrome

<Note type="warning">
  Chrome's implementation of [built-in AI with Gemini
  Nano](https://developer.chrome.com/docs/ai/built-in) is experimental and will
  change as they test and address feedback.
</Note>

Chrome built-in AI is a preview feature, you need to use chrome version 127 or greater, now in [dev](https://www.google.com/chrome/dev/?extra=devchannel) or [canary](https://www.google.com/chrome/canary/) channel, [may release on stable chanel at Jul 17, 2024](https://chromestatus.com/roadmap).

After then, you should turn on these flags:

- [chrome://flags/#prompt-api-for-gemini-nano](chrome://flags/#prompt-api-for-gemini-nano): `Enabled`
- [chrome://flags/#optimization-guide-on-device-model](chrome://flags/#optimization-guide-on-device-model): `Enabled BypassPrefRequirement`
- [chrome://components/](chrome://components/): Click `Optimization Guide On Device Model` to download the model.

## Language Models

The `chromeai` provider instance is a function that you can invoke to create a language model:

```ts
import { chromeai } from 'chrome-ai';

const model = chromeai();
```

It automatically selects the correct model id. You can also pass additional settings in the second argument:

```ts
import { chromeai } from 'chrome-ai';

const model = chromeai('generic', {
  // additional settings
  temperature: 0.5,
  topK: 5,
});
```

You can use the following optional settings to customize:

- **modelId** _'text' | 'generic'_

  Used to distinguish models of Gemini Nano, there is no difference in the current version.

- **temperature** _number_

  The value is passed through to the provider. The range depends on the provider and model.
  For most providers, `0` means almost deterministic results, and higher values mean more randomness.

- **topK** _number_

  Only sample from the top K options for each subsequent token.

  Used to remove "long tail" low probability responses.
  Recommended for advanced use cases only. You usually only need to use temperature.

## Examples

You can use Chrome built-in language models to generate text with the `generateText` or `streamText` function:

```javascript
import { generateText } from 'ai';
import { chromeai } from 'chrome-ai';

const { text } = await generateText({
  model: chromeai(),
  prompt: 'Who are you?',
});

console.log(text); //  I am a large language model, trained by Google.
```

```javascript
import { streamText } from 'ai';
import { chromeai } from 'chrome-ai';

const { textStream } = streamText({
  model: chromeai(),
  prompt: 'Who are you?',
});

let result = '';
for await (const textPart of textStream) {
  result = textPart;
}

console.log(result);
//  I am a large language model, trained by Google.
```

Chrome built-in language models can also be used in the `generateObject` function:

```javascript
import { generateObject } from 'ai';
import { chromeai } from 'chrome-ai';
import { z } from 'zod';

const { object } = await generateObject({
  model: chromeai('text'),
  schema: z.object({
    recipe: z.object({
      name: z.string(),
      ingredients: z.array(
        z.object({
          name: z.string(),
          amount: z.string(),
        }),
      ),
      steps: z.array(z.string()),
    }),
  }),
  prompt: 'Generate a lasagna recipe.',
});

console.log(object);
// { recipe: {...} }
```

<Note>
  Due to model reasons, `toolCall` and `streamObject` are not supported. We are
  making an effort to implement these functions by prompt engineering.
</Note>
