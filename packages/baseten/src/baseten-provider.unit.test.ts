import { describe, it, expect, vi, beforeEach, Mock } from 'vitest';
import { createBaseten } from './baseten-provider';
import {
  LanguageModelV2,
  EmbeddingModelV2,
  NoSuchModelError,
} from '@ai-sdk/provider';
import { loadApiKey } from '@ai-sdk/provider-utils';
import {
  OpenAICompatibleChatLanguageModel,
  OpenAICompatibleEmbeddingModel,
} from '@ai-sdk/openai-compatible';

// Mock the OpenAI-compatible classes
const OpenAICompatibleChatLanguageModelMock =
  OpenAICompatibleChatLanguageModel as unknown as Mock;
const OpenAICompatibleEmbeddingModelMock =
  OpenAICompatibleEmbeddingModel as unknown as Mock;

vi.mock('@ai-sdk/openai-compatible', () => {
  const createMockConstructor = (providerName: string) => {
    const mockConstructor = vi.fn().mockImplementation(function (
      this: any,
      modelId: string,
      settings: any,
    ) {
      this.provider = providerName;
      this.modelId = modelId;
      this.settings = settings;
      this.doGenerate = vi.fn();
      this.doEmbed = vi.fn();
    });
    return mockConstructor;
  };

  return {
    OpenAICompatibleChatLanguageModel: createMockConstructor('baseten.chat'),
    OpenAICompatibleEmbeddingModel: createMockConstructor('baseten.embedding'),
  };
});

vi.mock('@ai-sdk/provider-utils', () => ({
  loadApiKey: vi.fn().mockReturnValue('mock-api-key'),
  withoutTrailingSlash: vi.fn(url => url),
}));

describe('BasetenProvider', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  describe('createBaseten', () => {
    it('should create a BasetenProvider instance with default options', () => {
      const provider = createBaseten();
      const model = provider.chatModel('deepseek-ai/DeepSeek-V3-0324');

      const constructorCall =
        OpenAICompatibleChatLanguageModelMock.mock.calls[0];
      const config = constructorCall[1];
      const headers = config.headers();

      expect(loadApiKey).toHaveBeenCalledWith({
        apiKey: undefined,
        environmentVariableName: 'BASETEN_API_KEY',
        description: 'Baseten API key',
      });
      expect(headers.Authorization).toBe('Bearer mock-api-key');
      expect(config.provider).toBe('baseten.chat');
    });

    it('should create a BasetenProvider instance with custom options', () => {
      const options = {
        apiKey: 'custom-key',
        baseURL: 'https://custom.url',
        headers: { 'Custom-Header': 'value' },
      };
      const provider = createBaseten(options);
      const model = provider.chatModel('deepseek-ai/DeepSeek-V3-0324');

      const constructorCall =
        OpenAICompatibleChatLanguageModelMock.mock.calls[0];
      const config = constructorCall[1];
      const headers = config.headers();

      expect(loadApiKey).toHaveBeenCalledWith({
        apiKey: 'custom-key',
        environmentVariableName: 'BASETEN_API_KEY',
        description: 'Baseten API key',
      });
      expect(headers['Custom-Header']).toBe('value');
    });

    it('should support optional modelId parameter', () => {
      const provider = createBaseten();

      // Should work without modelId
      const model1 = provider();
      expect(model1).toBeInstanceOf(OpenAICompatibleChatLanguageModel);

      // Should work with modelId
      const model2 = provider('deepseek-ai/DeepSeek-V3-0324');
      expect(model2).toBeInstanceOf(OpenAICompatibleChatLanguageModel);
    });
  });

  describe('chatModel', () => {
    it('should construct a chat model with correct configuration for default Model APIs', () => {
      const provider = createBaseten();
      const modelId = 'deepseek-ai/DeepSeek-V3-0324';

      const model = provider.chatModel(modelId);

      expect(model).toBeInstanceOf(OpenAICompatibleChatLanguageModel);
      expect(OpenAICompatibleChatLanguageModelMock).toHaveBeenCalledWith(
        modelId,
        expect.objectContaining({
          provider: 'baseten.chat',
          errorStructure: expect.any(Object),
        }),
      );
    });

    it('should construct a chat model with optional modelId', () => {
      const provider = createBaseten();

      // Should work without modelId
      const model1 = provider.chatModel();
      expect(model1).toBeInstanceOf(OpenAICompatibleChatLanguageModel);
      expect(OpenAICompatibleChatLanguageModelMock).toHaveBeenCalledWith(
        'chat',
        expect.any(Object),
      );

      // Should work with modelId
      const model2 = provider.chatModel('deepseek-ai/DeepSeek-V3-0324');
      expect(model2).toBeInstanceOf(OpenAICompatibleChatLanguageModel);
    });

    it('should handle /sync/v1 endpoints correctly', () => {
      const provider = createBaseten({
        modelURL:
          'https://model-123.api.baseten.co/environments/production/sync/v1',
      });

      const model = provider.chatModel();

      expect(model).toBeInstanceOf(OpenAICompatibleChatLanguageModel);
      expect(OpenAICompatibleChatLanguageModelMock).toHaveBeenCalledWith(
        'placeholder',
        expect.objectContaining({
          provider: 'baseten.chat',
          url: expect.any(Function),
          errorStructure: expect.any(Object),
        }),
      );

      // Test URL construction
      const constructorCall =
        OpenAICompatibleChatLanguageModelMock.mock.calls[0];
      const config = constructorCall[1];
      const url = config.url({ path: '/chat/completions' });
      expect(url).toBe(
        'https://model-123.api.baseten.co/environments/production/sync/v1/chat/completions',
      );
    });

    it('should throw error for /predict endpoints with chat models', () => {
      const provider = createBaseten({
        modelURL:
          'https://model-123.api.baseten.co/environments/production/predict',
      });

      expect(() => {
        provider.chatModel();
      }).toThrow(
        'Not supported. You must use a /sync/v1 endpoint for chat models.',
      );
    });
  });

  describe('languageModel', () => {
    it('should be an alias for chatModel', () => {
      const provider = createBaseten();
      const modelId = 'deepseek-ai/DeepSeek-V3-0324';

      const chatModel = provider.chatModel(modelId);
      const languageModel = provider.languageModel(modelId);

      expect(chatModel).toBeInstanceOf(OpenAICompatibleChatLanguageModel);
      expect(languageModel).toBeInstanceOf(OpenAICompatibleChatLanguageModel);
    });

    it('should support optional modelId parameter', () => {
      const provider = createBaseten();

      const model1 = provider.languageModel();
      expect(model1).toBeInstanceOf(OpenAICompatibleChatLanguageModel);

      const model2 = provider.languageModel('deepseek-ai/DeepSeek-V3-0324');
      expect(model2).toBeInstanceOf(OpenAICompatibleChatLanguageModel);
    });
  });

  describe('textEmbeddingModel', () => {
    it('should throw error when no modelURL is provided', () => {
      const provider = createBaseten();

      expect(() => {
        provider.textEmbeddingModel();
      }).toThrow(
        'No model URL provided for embeddings. Please set modelURL option for embeddings.',
      );
    });

    it('should construct embedding model for /sync endpoints', () => {
      const provider = createBaseten({
        modelURL:
          'https://model-123.api.baseten.co/environments/production/sync',
      });

      const model = provider.textEmbeddingModel();

      expect(model).toBeInstanceOf(OpenAICompatibleEmbeddingModel);
      expect(OpenAICompatibleEmbeddingModelMock).toHaveBeenCalledWith(
        'embeddings',
        expect.objectContaining({
          provider: 'baseten.embedding',
          url: expect.any(Function),
          errorStructure: expect.any(Object),
        }),
      );

      // Test URL construction for embeddings (Performance Client adds /v1/embeddings)
      const constructorCall = OpenAICompatibleEmbeddingModelMock.mock.calls[0];
      const config = constructorCall[1];
      const url = config.url({ path: '/embeddings' });
      expect(url).toBe(
        'https://model-123.api.baseten.co/environments/production/sync/v1/embeddings',
      );
    });

    it('should throw error for /predict endpoints (not supported with Performance Client)', () => {
      const provider = createBaseten({
        modelURL:
          'https://model-123.api.baseten.co/environments/production/predict',
      });

      expect(() => {
        provider.textEmbeddingModel();
      }).toThrow('Not supported. You must use a /sync or /sync/v1 endpoint for embeddings.');
    });

    it('should support /sync/v1 endpoints (strips /v1 before passing to Performance Client)', () => {
      const provider = createBaseten({
        modelURL:
          'https://model-123.api.baseten.co/environments/production/sync/v1',
      });

      const model = provider.textEmbeddingModel();

      expect(model).toBeInstanceOf(OpenAICompatibleEmbeddingModel);
      expect(OpenAICompatibleEmbeddingModelMock).toHaveBeenCalledWith(
        'embeddings',
        expect.any(Object),
      );
    });

    it('should support custom modelId for embeddings', () => {
      const provider = createBaseten({
        modelURL:
          'https://model-123.api.baseten.co/environments/production/sync',
      });

      const model = provider.textEmbeddingModel();

      expect(model).toBeInstanceOf(OpenAICompatibleEmbeddingModel);
      expect(OpenAICompatibleEmbeddingModelMock).toHaveBeenCalledWith(
        'embeddings',
        expect.any(Object),
      );
    });
  });

  describe('imageModel', () => {
    it('should throw NoSuchModelError for unsupported image models', () => {
      const provider = createBaseten();

      expect(() => {
        provider.imageModel('test-model');
      }).toThrow(NoSuchModelError);
    });
  });

  describe('URL construction', () => {
    it('should use default baseURL when no modelURL is provided', () => {
      const provider = createBaseten();
      const model = provider.chatModel('test-model');

      const constructorCall =
        OpenAICompatibleChatLanguageModelMock.mock.calls[0];
      const config = constructorCall[1];
      const url = config.url({ path: '/chat/completions' });
      expect(url).toBe('https://inference.baseten.co/v1/chat/completions');
    });

    it('should use custom baseURL when provided', () => {
      const provider = createBaseten({
        baseURL: 'https://custom.baseten.co/v1',
      });
      const model = provider.chatModel('test-model');

      const constructorCall =
        OpenAICompatibleChatLanguageModelMock.mock.calls[0];
      const config = constructorCall[1];
      const url = config.url({ path: '/chat/completions' });
      expect(url).toBe('https://custom.baseten.co/v1/chat/completions');
    });

    it('should use modelURL for custom endpoints', () => {
      const provider = createBaseten({
        modelURL:
          'https://model-123.api.baseten.co/environments/production/sync/v1',
      });
      const model = provider.chatModel();

      const constructorCall =
        OpenAICompatibleChatLanguageModelMock.mock.calls[0];
      const config = constructorCall[1];
      const url = config.url({ path: '/chat/completions' });
      expect(url).toBe(
        'https://model-123.api.baseten.co/environments/production/sync/v1/chat/completions',
      );
    });
  });

  describe('Headers', () => {
    it('should include Authorization header with API key', () => {
      const provider = createBaseten();
      const model = provider.chatModel('test-model');

      const constructorCall =
        OpenAICompatibleChatLanguageModelMock.mock.calls[0];
      const config = constructorCall[1];
      const headers = config.headers();

      expect(headers.Authorization).toBe('Bearer mock-api-key');
    });

    it('should include custom headers when provided', () => {
      const provider = createBaseten({
        headers: { 'Custom-Header': 'custom-value' },
      });
      const model = provider.chatModel('test-model');

      const constructorCall =
        OpenAICompatibleChatLanguageModelMock.mock.calls[0];
      const config = constructorCall[1];
      const headers = config.headers();

      expect(headers.Authorization).toBe('Bearer mock-api-key');
      expect(headers['Custom-Header']).toBe('custom-value');
    });
  });

  describe('Error handling', () => {
    it('should handle missing modelURL for embeddings gracefully', () => {
      const provider = createBaseten();

      expect(() => {
        provider.textEmbeddingModel();
      }).toThrow(
        'No model URL provided for embeddings. Please set modelURL option for embeddings.',
      );
    });

    it('should handle unsupported image models', () => {
      const provider = createBaseten();

      expect(() => {
        provider.imageModel('unsupported-model');
      }).toThrow(NoSuchModelError);
    });
  });

  describe('Provider interface', () => {
    it('should implement all required provider methods', () => {
      const provider = createBaseten();

      expect(typeof provider).toBe('function');
      expect(typeof provider.chatModel).toBe('function');
      expect(typeof provider.languageModel).toBe('function');
      expect(typeof provider.textEmbeddingModel).toBe('function');
      expect(typeof provider.imageModel).toBe('function');
    });

    it('should allow calling provider as function', () => {
      const provider = createBaseten();

      const model1 = provider();
      expect(model1).toBeInstanceOf(OpenAICompatibleChatLanguageModel);

      const model2 = provider('test-model');
      expect(model2).toBeInstanceOf(OpenAICompatibleChatLanguageModel);
    });
  });
});
