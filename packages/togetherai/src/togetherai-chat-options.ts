// https://docs.together.ai/docs/serverless-models#chat-models
export type TogetherAIChatModelId =
  | 'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8'
  | 'meta-llama/Llama-4-Scout-17B-16E-Instruct'
  | 'meta-llama/Llama-3.3-70B-Instruct-Turbo'
  | 'meta-llama/Llama-3.2-3B-Instruct-Turbo'
  | 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo'
  | 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo'
  | 'meta-llama/Meta-Llama-3-8B-Instruct-Lite'
  | 'meta-llama/Llama-3-70b-chat-hf'
  | 'meta-llama/Llama-3-8b-chat-hf'
  | 'marin-community/marin-8b-instruct'
  | 'nvidia/Llama-3.1-Nemotron-70B-Instruct-HF'
  | 'Qwen/Qwen3-235B-A22B-fp8-tput'
  | 'Qwen/Qwen2.5-Coder-32B-Instruct'
  | 'Qwen/QwQ-32B'
  | 'Qwen/Qwen2.5-7B-Instruct-Turbo'
  | 'Qwen/Qwen2.5-72B-Instruct-Turbo'
  | 'Qwen/Qwen2-72B-Instruct'
  | 'google/gemma-2-27b-it'
  | 'google/gemma-2b-it'
  | 'arcee-ai/virtuoso-large'
  | 'arcee-ai/virtuoso-medium-v2'
  | 'arcee-ai/coder-large'
  | 'deepseek-ai/DeepSeek-V3'
  | 'deepseek-ai/DeepSeek-R1'
  | 'deepseek-ai/DeepSeek-R1-Distill-Llama-70B'
  | 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B'
  | 'Gryphe/MythoMax-L2-13b'
  | 'mistralai/Mistral-Small-24B-Instruct-2501'
  | 'mistralai/Magistral-Small-2506'
  | 'mistralai/Mistral-7B-Instruct-v0.1'
  | 'mistralai/Mistral-7B-Instruct-v0.2'
  | 'mistralai/Mistral-7B-Instruct-v0.3'
  | 'mistralai/Mixtral-8x7B-Instruct-v0.1'
  | 'NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO'
  | (string & {});
